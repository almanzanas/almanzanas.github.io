{
  "hash": "ce724d31fc89b57c3bf5a151f93201da",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Functions, scripts and performance\"\n\n---\n\n\n# Writing Functions and Scripts\n\nTo accomplish repetitive task in data cleaning we are use functions and scripts.\n\n## Functions\n\nA function starts with the reserved word `function`. Continue with a a list of arguments inside parentheses. Then the body of the function enclosed in braces. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsqplus <- function (x, y = 2) {\n    # y default value is 2\n    # Args: x, numeric;\n    #       y, numeric;\n    if (x < 0) {\n        warning (\"Negative number cannot be operated\")\n        return (NA)\n    }\n    return (sqrt (x) + y)\n}\n# Trying the new function 'sqplus'\nsqplus (x=9, y=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n:::\n\n\nThe ellipsis `(...)` is a special type of argument which captures all of the arguments that are not matched. If the ellipsis is the first argument, the rest of arguments have to match by name, without abbreviation. The `missing()` function returns `TRUE` if an argument is missing. When it is used inside a function should be located near the beginning. For example, if 'arg' gets assigned in code, then `missing(arg)` will be `FALSE.`\n\nA *local variable* is one that exists inside the created function, stored in a special area of memory by R. The *global variables* are in the workspace. It should be avoided to use the created variable of the workspace into functions, because it can change, otherwise the built-in variables (pi or letters) it's OK. \n\nThe *return value* is the result of the computation done by the function. A function returns whatever is inside the first call to `return()`; when `return()` is missing, the function returns whatever the last line it executes produces. The return can be hidden with `invisible()` command, but if you assign the output, the return value will be stored.\n\nTo create functions R provides with `fix()` function which open an editor to write that new function. If the passing function name with `fix()` already exists it will open the existing function for editing. When it saves, R checks to see if the new version of the function has no errors. If there is an error you can use `edit()` function (immediately after encountering an error) without argument to operate on the most recently edited function.\n\nUsing the `dump()` command creates a disk file with the exact text of the function. The first argument for `dump()` is a vector of the names of the items to be dumped, and the second argument is the file name ( `dump(\"func1\", \"func1.txt\")` ). Once is on disk, it can be read with `source()` which also executes the code in your R session ( `source(\"func1.txt\")` ). Also, if the function already exists, it will overwrite the function.\n\nWhen we want to save complicated objects, the function `saveRDS()` will save on disk a binary file with that objects data and attributes ( `saveRDF(robj, \"robjfile\")` ). The, with `readRDS()` function returns the object just as it was saved, it won't replace the object, simply returns it.\n\nAnd finally, `save()` function operates on sets of objects passing the object's names in quotation marks. The complementary function is `load()` and re-creates the items specified at the time the file was created, with their original names (R will over-write existing objects with that names).\n\n## Scripts\n\nA **script** (created under 'File/New file/R Script') contain R commands, comments, musings, invalid code for fixing... Usually, the script will be visible in a separate windows as interactive usage. The commands can be run by line with 'Control+Enter' where the mouse is, or selecting some lines. \n\nThe scripts store a lot of the commands to use and often are run bit by bit interactively. If a line have an error, R will continue running all the commands. Also we can run a script all at one with the `source()` function and only the commands prior to the error are executed. \n\nA **shell script** is useful in a production environment where a specific task needs to be performed frequently. It is intended to be run a.l at once, not as part of an interactive session. Also can be run with `source()`. A script run with R, meanwhile a shell script run from a command line without having to open R.\n\nThe program 'Rscript' run shell scripts which the first line specify `#!Rscript` . Once the run is finished, returns to the command line. Normally are useful for produce output files, graphics, informative messages. With the command `Rscript --help` will show options when running shell scripts.\n\nIn a script a function is an entire unit but a script run line by line:\n\n```r\n# Function that will fail\nif (i > 100)\n    x <- x + 200\nelse\n    x <- x - 200\n```\n\nThe functions have to be 'protected' with brace. Here the second line does not end the expression because there is still an open brace:\n\n```r\nif (i > 100) {\n    x <- x + 200\n} else {\n    x <- x - 200\n}\n```\n\nWhat to do? Well, functions use local variables and when it's saved R examine the functions for errors; also it has to run all at once. Scripts can be run line by line and passed as text files; however they only create global variables, and then can over-write exiting objects.\n\n## Error Handling\n\n### Debugging with `cat()`\n\nInsert `cat()` statements into the code at strategic locations to print results. When you see an error inserting before a `cat()` function to check the previous results is a good idea, and also labeling the statements to know where they are placed.\n\nIf you have a loop variable you can use `if(i %% 100 == 0) cat(\"We're on rep n \", i, \"\\n\")` which will print a line every 100 iterations.\n\n### Debugging with `traceback()`, `browser()` and `debug()`\n\nWhen we don't know where the error is (can be nested or whatever) a call to `traceback()` show the sequence of function calls that led to the error. For advance users, the `recover()` function lists the set of calls and starts a browser session in the one that the user selects.\n\nWhen a function or script encounters a call to `browser()`, it pauses and produce a prompt:\n\n```r\nBrowse[1]> \n```\n\nThe `[1]` indicates that was called at the command line; `[2]` for a function called by a function; higher values for more nested function calls. There we can type the name of an object to display it, enter other function calls, create local variables... Usually it is used to display or modify the values of variables in the function. Also `browser()` has special commands:\n\n-   `c` : continue, resume running.\n-   `s` : step, go to the next statement (also inside other functions).\n-   `n` : next, go to the next statement.\n-   `f` : finish, to finish the loop or function.\n-   `Q` : quit the browser.\n\nInside a function with `ls()` we ca see only the local variables of that function, and to see the global variables is `ls(pos = 1)`.\n\nIn a script we can use `verbose=` as an argument and as part of the script to print different messages. Also can be added an argument called `browse=` that specifies where calls to `browser()` might be made (but ensure by default is `FALSE`). If `verbose=` is `TRUE` or with a specific number it will print some messages while the script runs:\n\n```r\nprocess_file <- function(fname, verbose = 0) {\n\n  if (verbose >= 1) {\n    cat(\"Now operating on file\", fname, \"\\n\")\n  }\n  \n  # Rest of the code\n  # ...\n  \n  if (verbose >= 2) {\n    cat(\"Detailed diagnostics: Finished processing file\", fname, \"\\n\")\n  }\n  \n}\n\n# Function with different verbose levels\nprocess_file(\"data.csv\", verbose = 1)\nprocess_file(\"data.csv\", verbose = 2)\n\n```\n\nFinally, `debug()` function labels a function to be 'browsed' whenever it runs. This persists until `undebug()` remove the label; and with `debugonce()` label a function for just once run. Debugging produce the browser prompt, save us to include the explicit call to `browse()` inside a function.\n\n### Issuing Error and Warning Messages\n\nWherever the function `stop()` is it will stop the function and print a message. A common function of `stop()` is to test whether the arguments are of the expected type. The `stopifnot()` function acts like `stop()`, but if any expressions are not all `TRUE` stops and produce an error message indicating the first expression which was not `TRUE`.\n\n```r\nif(!is.matrix(x)) stop(\"X must be matrix\")\n\n# Check which could be false:\nif(any(is.na (b)) || any(b < 0)) { stop(\"Illegal argument b\") }\n# The double || OR would stop evaluating if the first any() is TRUE.\n# Then, if it's TRUE, we could add:\nstopifnot(b > 0)\n```\n\nWhen it's not necessary to stops the function, `warning()` function prints out text supplied by the function (often after a call to `paste()` assembling some diagnostic info) and the function attempts to continue.\n\nIf more then 10 warning messages are generated, don't be displayed, we can call to `warnings()` to access the messages.\n\nThe `try()` function lets to try a expression and if fails return an object class 'try-error'. It is useful when we are relying on programs and files outside R's control.\n\n```r\na <- function (arg1) {\n    if (missing (arg1)) stop (\"Missing argument in a!\")\n    return (arg1^2)\n}\n\nb <- function (input = 9, offset) {\n    a.result <- a (offset)\n    return (input + a.result)\n}\n\nb()\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraceback()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNo traceback available \n```\n\n\n:::\n:::\n\n\nReading from bottom to top of the `traceback()` output, we can see the error in a call to `b()`, which called `a()` at line #2 of the `b()` function, and the error took place at the second line of `a()`.\n\nThis is the same function but in this version using `try()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb <- function (input = 9, offset) {\n    a.check <- try (a.result <- a (offset) )\n    if (class (a.check)[1] == \"try-error\") {\n        warning (\"Call to a() failed; setting a.result = 3\")\n        a.result <- 3\n    }\n    return (input + a.result)\n}\n\nb()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nError in a(offset) : could not find function \"a\"\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in b(): Call to a() failed; setting a.result = 3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n:::\n\n\nLots of R objects returns a vector of classes when we use `class()` function, that's why we specified `class(a.check)[1]`.\n\n## Interacting with the OS\n\nBy default R presumes that is dealing with files in the working directory. The `getwd()` command prints the working directory and with `setwd()` we can change to a new location.\n\n-   `list.files()` : list the files in the working directory (without arguments). \n    -   `full.names=` if `TRUE` list the files in a vector of directories, returns a path name.\n    -   `recursive=` if `TRUE` find files in the working directory and subdirectories.\n    -   `pattern=` to pass a regular expression, such as \"`xlsx*$`\" for excel files.\n    -   `ignore.case=` if `TRUE` will ignore upper- and lower-case.\n-   `file.info()` : gives information about a file. Can be passed an absolute path for a file outside the working directory.\n-   `file.copy(), file.exists(), file.remove()`\n-   `dir.exists(), dir.create()`\n\nTo list the Environment Variables we can use the function `Sys.getenv()`, as an argument we can specified a variable to extract. `R_HOME` for example gives the directory where R is installed. Also, to create or update variables is the command `Sys.setenv()` where we can pass a variable name and a value like `Sys.setenv(REPS = 12)`. This is a way to pass information from \"outside\" into R.\n\n## Speeding process\n\nProfiling is the process of measuring how much time and memory a function uses. The `Rprof()` function can help to identify both the steps that use time and memory. The function writes a log file, then with `summaryRprof()` we can get a report.\n\nUsing a vectorized function on a vector will almost always be more efficient than looping over the individual entries. If it's possible to replace a for() or while() loop with an apply() the result will be faster, more efficient. In large data sets where there are more many rows than columns, the point is to try to avoid loop over rows because looping over columns is usually much less costly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Non-Vectorized:\nf1 <- function (x, y = 2) {\n    if (x < 0) {\n        warning (\"Neg(s)\")\n        return (NA)\n    }\n    return (sqrt(x) + y)\n}\nf1(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.236068\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Vectorized\nf2 <- function (x, y = 2) {\n    out <- as.numeric (rep(NA, length(x)))\n    if (any(x < 0)) warning (\"Neg(s)\")\n    out[x >= 0] <- sqrt(x[x > 0]) + y\n    return (out)\n}\nf2(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.236068\n```\n\n\n:::\n:::\n\n\nIn the vectorized version we create an `out` vector filled with `NA` values and then only will fill the values which are `x >= 0` . Also, we use `as.numeric()` because by default NA values are logical which shouldn't be an issue but just in case.\n\nVectorization makes code harder and slower to write, maybe the time of develop a simple code, run, explain and maintain it, it is more 'person' efficient than write it vectorized.\n\nCompiling is other way to speed up the code. It is the translation of R code into 'byte' code. The package `compile` allow to compile our functions, one at a time with `cmpfun()` (or `compile()` for expressions); or using `compilePKGS()` to compile package by package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwhat <- function (n = 100) {\n    for (i in 1:n) {}\n}\n# timing the function 'what' n=6,000,000,000\nsystem.time (what (6e9) )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  39.48    0.01   43.06 \n```\n\n\n:::\n\n```{.r .cell-code}\n# compiling and testing again: \nlibrary(compiler)\nwhat.cmp <- cmpfun(what)\nsystem.time (what.cmp (6e9))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n  40.44    0.02   43.10 \n```\n\n\n:::\n:::\n\n\nThe previous result with `system.time()` will depends on how fast the computer is. Another approach is `enableJIT()` (or 'just-in-time' compilation) which given a number to specify how the compilation should work. For example, `enableJIT(3)` performs as much compilation as possible. Once we make this call, functions are compiled before their first use and will remain compiled. To 'uncompile' a function we can edit it with `fix()`, also it is possible to convert it into text like `what.cmp <- eval(parse(text=deparse(what.cmp, control=\"useSource\")))`.\n\n**Parallel Processing** can speed the things up using multiple cores of our computer. The package `parallel` allows control over the use of multiple cores. To know how many cores it has the function `detectCores()` will tell us. Requires three steps to use parallel: a cluster of cores with `makeCluster()` once per session; any necessary items from the global workspace need to be passed to the cluster with `clusterExport()`; and the cluster is passed to one of the functions that knows how to use it.\n\n-   `parSapply()` : acts like `sapply()` but with parallel processing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parallel)\ndetectCores()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 16\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nclust <- makeCluster(10)\nclusterExport (clust, c(\"what\", \"what.cmp\"))\nsystem.time (\n    parSapply (clust, 1:10, function (i) what (6e9/10))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n      0       0       5 \n```\n\n\n:::\n\n```{.r .cell-code}\nsystem.time (\n    parSapply(clust, 1:10, function (i) what.cmp (6e9/10))\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   user  system elapsed \n   0.00    0.00    5.39 \n```\n\n\n:::\n:::\n\n\nFunction inside `parSapply()` are not compiled when `enableJIT()` is enabled, have to been compiled explicitly (or run the function first and then export it).\n\nIt is a good practice to stop the cluster with `stopCluster()` when parallel processing is complete.\n\nFor the last bit of information, R can interface with code in machine level, often originally written in C or Fortran. We run code like this all the time without knowing it.\n\n## To remember\n\nBe consistent with the code you write. Use comments to explain the code. The blank lines, spaces, indentation are useful to make de code readable.\n\n-   Many bugs arise from unexpected input. Check NA values with `anyNA()` or using `na.rm=TRUE` argument in some functions. \n-   R sometimes convert one row or column to a vector, and then when we want to use that column (matrix), often the function will be expecting a matrix not a vector. \n-   Take care to missing values propagating through computations. \n-   Ensure that files, paths and folders exists and can be accessible, file.exists() and file.info() to see if a file is writable.\n-   Some functions expects a single result, but using `if(class(obj) == \"lm\")` can produce a warning because often `class()` could return a vector of classes. Then `class(obj)[1]` will work.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}