---
title: "Transformations with Tidyverse"
---

Dataset: https://archive.ics.uci.edu/ml/datasets/Adult

```{r}
#install.packages('tidyverse')
library(tidyverse)
```

Tidy data is one observation per row, one measurement or variable per column and one value per cell.

```{r}
header <- c("age", "workclass", "fnlwgt","education",
"education_num", "marital_status", "occupation",
"relationship", "race", "sex", "capital_gain", "capital_loss","hours_per_week", "native_country", "target")

df <- read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data", col_names = header, 
                   trim_ws = TRUE)

head(df)
```

# Slicing and filtering

The basic form of dplyr for slicing it to use a `.` to consider everything from the object that precedes it. The returned object will be a tibble.

```{r}
df %>% .[1:4, c(2:5)]
```

-   `slice_min(), slice_max()`: to fetch the top or bottom observation given a percentage.
-   `slice_sample()`: to extract a sample.

```{r}
df %>% slice_min(age, prop = 0.15)
```
```{r}
df %>% slice_sample(n=10, replace = FALSE) %>% .[,1:4]
```

## Filtering

-   `filter()`: returns rows given a condition.
-   `select()`: to choose variable to show in the given order.

```{r}
df %>%
  filter( age < 30 ) %>%
  select( marital_status, age, education ) %>%
  slice_sample( n = 10)
```

- distinct(): to extract unique values.

```{r}
df %>% distinct(sex) 
```

# Grouping and summarizing data

The next functions are complementary, usually used together.

-   `group_by()`: to group a variable by its values
-   `summarize()`: given a function with a variable returns the result.
-   `ungroup()`: after `group_by()` with more than one variable, it returns a `tbl_df`. The ungrouped tibble requires less memory space than the tibble one.

```{r}
df %>% group_by(workclass) %>% .[1:10,1:4]
```
```{r}
df %>% group_by(sex) %>% summarise( avg_age = mean(age), sd_age = sd(age))
```
```{r}
marital.groups <- df %>% group_by(marital_status, sex) %>%
  summarize( avg_age = mean(age) )
marital.groups
```
```{r}
ungroup(marital.groups)
```

-   `quantile()`: returns the number corresponding the passing percentage.
-   `first()`: returns the first number. Combined with `group_by()` returns the first number of each group.
-   `across()`: applies a function to the selected columns.

```{r}
df %>% group_by(marital_status) %>% summarise(first(age))
```
```{r}
df %>% group_by(sex) %>% summarise( "50%" = quantile(age, 0.5))
```
```{r}
df %>% select(1,3,5,11,12,13) %>%
  summarise( across(everything(), mean) )
```

# Replacing and Filling Data

A dataset will be imperfect, in this case we have '?' instead of NA. First, the character '?' has to be replaced with NA and then we can replace NA with other character.

```{r}
for (var in colnames(df) ) {
    print(
        paste (var, nrow( df[df[var] == '?', ] ) )
    )
}
```

In the output we can see the missing values represented with '?': "workclass 1836", "occupation 1843", and "native_country 583". Now we can use `mutate()` to edit the columns affected.

```{r}
df.rep <- df %>%
    mutate (workclass = replace(workclass, workclass == '?', NA),
            occupation = replace(occupation, occupation == '?', NA),
            native_country = replace(native_country, native_country == '?', NA)
            )

slice_sample( df.rep[which(is.na(df.rep["workclass"])),], n=10 )
```

One alternative can be to use `across(everything())` to replace with `ifelse()`:

```{r}
df.rep <- df %>% 
      mutate( across( everything(), ~ ifelse( . == '?', NA, . ) ) )

df.rep[which(is.na(df.rep["workclass"])),]
```

To handle missing values we can drop them, filling them with the previous or next valid value, or replacing them with a statistic value, such as the mean value.

-   `fill()`: Fills missing values in selected columns using the next or previous entry.
    -   `.direction=` to choose the direction of the fill (down, up, downup, updown).

```{r}
df.rep.na.ind <- which(is.na(df.rep["occupation"]))

df.rep %>% fill (workclass, occupation, native_country,
                 .direction = "down") %>%
    .[df.rep.na.ind,] %>%
    slice_sample(n=10)
```

When the variable is categorical it is common to replace the missing values with the most common category. 

>Every change in a dataset is a decision that the data scientist has to make and <b>it will certainly affect the result</b>

This is how we can replace NA with the most frequent value on the categorical variables. First we have to found that value using `table()` with `which.max()`. Then we can use that to replace NA with `replace_na()` pointing both columns.

```{r}
# Most frequent value
m.f.workcls <- names( table(df$workclass)[which.max(table(df$workclass))])
m.f.occp <- names( table(df$occupation)[which.max(table(df$occupation))])

# Replacing NA
df.no.na <- df.rep %>% replace_na( list( workclass = m.f.workcls,
                                         occupation = m.f.occp) )

slice_sample( df.no.na[df.rep.na.ind,], n=10)
```

At this point, the data frame only have NA values in native_country. If the NA is less than 5% of the total observation we could drop that observations. With 'workclass' and 'occupation' this percentage was bigger than 5% but on 'native_country' is less than 2%.

```{r}
# Drop NA
df.no.na <- df.no.na %>% drop_na()
```

Example to extract NA percentage:

```{r}
# Get proportions with table()
table(df.rep$occupation, useNA = 'ifany') %>% prop.table()

# Basic alternative
paste("NA percentage on 'occupation' variable: ",
    sum(is.na(df.rep$occupation)) / nrow(df.rep) * 100)
```

# Arranging data

-   `arrange()`: to order a data frame by a column to ascending order
    -   `desc()`: to change the order to descending

```{r}
df.no.na %>% arrange( desc(fnlwgt) ) %>% .[1:10,1:4]
```

Also can be useful with `group_by()`, for example:

```{r}
df.no.na %>%
    group_by(marital_status) %>%
    summarize( count = n() ,
               avg_net_gain = mean( capital_gain - capital_loss) ) %>%
    arrange( desc(avg_net_gain) )
```

# Creating new variables

We can create new variables such as splitting a column, creating a calculation, encoding text, applying a custom function...

-   `separate()`: to split a column into two column, by default remove the original column.
    -   `remove=` if `FALSE` to keep the original column
-   `unite()`: is the complementary function to separate(), is useful to create a unique identifier.
    -   `sep=` to specify the separator of the new column values
    -   `remove=FALSE` to keep the original column

```{r}
df.no.na %>% separate(target, into = c("sign", "amount"), sep = "\\b") %>%
    slice_sample(n=10) %>% .[,-(3:14)]
```
```{r}
df.no.na %>%
    unite( sex, race, age, col="description", sep="_", remove = FALSE) %>%
    select(sex, race, age, description, marital_status) %>%
    slice_sample(n=10)
```

## The `mutate()` function

-   `mutate()`: designed to create new variables. Also can be used to modified existing variables using the same column name. Given a data frame, then the new variable name equal to the values.
-   `recode()`: working as a mapping to transform variables

The new variable which you can create could be whatever are in our mind, a custom function, a simple calculation, a vector...

```{r}
df.no.na %>%
    mutate ( total_gain = capital_gain - capital_loss,
             tax = ifelse( total_gain >= 15000,
                           total_gain * 0.21,
                           total_gain * 0.1) ) %>%
    slice_sample(n=10) %>% select(total_gain, tax, occupation, age) %>%
    arrange ( desc(tax) )
```

Combining `mutate()` and `recode()` to transform values, useful for categories:

```{r}
df.no.na %>%
    mutate( over_under = recode ( target, '<=50'='under', '>50'='over') ) %>%
    select(target, over_under) %>%
    slice_sample(n=10)
```

For binning a new variable using `mutate()` in combination with `cut()`. To `cut()` will pass the column, a vector with the intervals, and a vector with the name of that intervals.

```{r}
df.no.na %>%
    mutate( age_avg = mean(age), 
            over_under_age_avg = cut( age,
                                      c(0, mean(age), max(age)),
                                      c('Lower than avg', 'Above the avg'))) %>%
    select (age, age_avg, over_under_age_avg) %>%
    slice_sample(n=10)
```

# Joining datasets

-   `left_join()`
-   `right_join()`
    -   `keep=` if `TRUE` cause the equal variables from both tables to repeat.
    -   `by=` passing a column to join. It could be passed two column which represent the same values, like `by=c('store_id'='id_store')`
-   `inner_join()`
-   `full_join()`
-   `anti_join()`

If in the previous join functions we don't pass id= argument, it will determine automatically on which column to join.

```{r}
sales <- data.frame(
  date = c("2022-01-01", "2022-01-02", "2022-01-03", "2022-01-04", "2022-01-05"),
  store_cd= c(1,2,3,4,5),
  product_cd= c(1,2,3,4,5),
  qty= c(10, 12, 9, 12,8), 
  sales= c(30, 60, 45, 24, 32)
  )

stores <- data.frame(
  store_cd= c(1,2,3,4,6),
  address= c('1 main st', '20 side st','19 square blvd','101 first st','1002 retail ave'),
  city= c('Main', 'East', 'West', 'North', 'South'), 
  open_hours= c('7-23', '7-23', '9-21', '9-21', '9-21')
  )

products <- data.frame(
  product_cd= c(1,2,3,4,6),
  description= c('Soft drink', 'Frozen snack', 'Fruit', 'Water', 'Fruit 2'),
  unit_price= c(3.0, 5.0, 5.0, 2.0, 4.0), 
  unit_measure= c('each', 'each', 'kg', 'each', 'kg')
  )
```

#### Left Join

```{r}
sales %>%
    left_join (products[,1:2], by='product_cd')
```

#### Right Join

```{r}
sales %>%
    select(store_cd, sales) %>%
    right_join(stores, by = 'store_cd')
```

#### Full Join

```{r}
sales %>% full_join(stores)
```

# Reshaping a table

A data frame in a wide shape is not suitable for machine learning algorithms and for most of the plotting functions. A wide format is when the variable are spread along the rows instead of columns.

-   `pivot_longer()`: given a wide data frame, it will shape it to long format.
    -   `cols=` to specify which columns should be reshaped, passing a range (`2:6`)
    -   `names_to=` passing a string as column name for the columns specified in `cols=` argument
    -   `values_to=` passing a column name for the column representing the values.
-   `pivot_wider()`: given a long data frame, it will shape it to wide format.
    -   `names_from=` passing a column name, will take that values to form column names.
    -   `values_from=` passing a column name, will take that values as values.

# Interesting Tidyverse functions

Using `data('mtcars')` dataset.

The `purrr` library contain functions similar to `apply()` family.

-   `map()`: applies the same function to every element of a vector or list.

From `dplyr` there are functions similar to `rbind()` and `cbind()`:

-   `bind_rows()`: the data frames must have the same columns
-   `bind_cols()`: the data frames must have the same number of observations.

Functions used alongside `mutate()` are cumutalive aggregate functions such as `cumsum(), cumprod(), cummean(), cummax(), cume_dist()`. This functions expect a variable name.

```{r}
library('datasets')
data('mtcars')

mtcars %>% mutate( cumsum_weight = cumsum(wt),
                   cumpct_weight = cume_dist(wt),
                   cummean_weight = cummean(wt) ) %>%
    select(wt, cumsum_weight, cumpct_weight, cummean_weight) %>%
    slice_sample(n=10) %>%
    arrange(cumpct_weight)
```

-   `case_when()`: also from `dplyr.` to deal with multiple cases of logical tests.
    -   As argument we pass a condition and what will return if it's `TRUE`, separated by `~`

```{r}
mtcars %>%
    mutate( transmission_type = case_when ( am == 0 ~ 'automatic',
                                            am == 1 ~ 'manual' ) ) %>%
    select(cyl, mpg, am, transmission_type) %>%
    slice_sample(n=10)
```

## `ggplot2`

As a briefly introduction to ggplot2, it is maybe considered one of the best tools for data visualization.

The syntax is: first, the `ggplot()` functions receives the data. Going forward we must link the layers using '`+`'. Then we choose the geometry corresponding the graphic type. In geometry we pass `aes()` with the axis inside like `aes(x, y, fill)`, and the color, size points and other arguments.

Let's try a scatterplot with mtcars dataset to view the relationship between 'miles per gallon' and 'horsepower':

```{r}
ggplot(data = mtcars) +
    geom_point( aes( x = hp, y = mpg),
                color = 'darkblue', size=4, alpha=0.5 ) +
    ggtitle("Relationship between HP vs MPG")
```
















